{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Lending Club Data Cleaning Code - Tim is a github superstar!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 of 3:\n",
    "This code should take Lending Club data and clean it for the purpose of modeling, this includes caping and flooring, imputing, and eliminating irrelevant columns. Throughout the code their are tests to make sure fields don't wildly shift from expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Import necessary Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np \n",
    "import statsmodels.formula.api as sm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Create Dictionary to track passes/failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###1) Create DF from downloaded CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine Historic Datasets from Lending Club\n",
    "dataSetA = '/Users/tphoran/Downloads/LoanStats3a_securev1.csv'\n",
    "dataSetB = '/Users/tphoran/Downloads/LoanStats3b_securev1.csv'\n",
    "dataSetC = '/Users/tphoran/Downloads/LoanStats3c_securev1.csv'\n",
    "\n",
    "def importCSVLendingClub(dataset, headerRows, footerRows, index):\n",
    "    # More info on read_csv http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "    return pd.io.parsers.read_csv(dataset,sep = ',', index_col = index, skiprows = headerRows, skipfooter = footerRows,  engine='python')\n",
    "    \n",
    "df_a = importCSVLendingClub(dataSetA, 1, 2, 'id')\n",
    "df_b = importCSVLendingClub(dataSetB, 1, 2, 'id')\n",
    "df_c = importCSVLendingClub(dataSetC, 1, 2, 'id')\n",
    "\n",
    "# More info on concat and drop_duplicate\n",
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html\n",
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop_duplicates.html\n",
    "df = pd.concat([df_a, df_b, df_c]).drop_duplicates()\n",
    "df = df[df['member_id'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test to see if columns have been added since code was initially built or datatype has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expected colunns as of 2015-09-03\n",
    "expected = [u'member_id', u'loan_amnt', u'funded_amnt', u'funded_amnt_inv', u'term', u'int_rate', u'installment', u'grade', u'sub_grade', u'emp_title', u'emp_length', u'home_ownership', u'annual_inc', u'verification_status', u'issue_d', u'loan_status', u'pymnt_plan', u'url', u'desc', u'purpose', u'title', u'zip_code', u'addr_state', u'dti', u'delinq_2yrs', u'earliest_cr_line', u'fico_range_low', u'fico_range_high', u'inq_last_6mths', u'mths_since_last_delinq', u'mths_since_last_record', u'open_acc', u'pub_rec', u'revol_bal', u'revol_util', u'total_acc', u'initial_list_status', u'out_prncp', u'out_prncp_inv', u'total_pymnt', u'total_pymnt_inv', u'total_rec_prncp', u'total_rec_int', u'total_rec_late_fee', u'recoveries', u'collection_recovery_fee', u'last_pymnt_d', u'last_pymnt_amnt', u'next_pymnt_d', u'last_credit_pull_d', u'last_fico_range_high', u'last_fico_range_low', u'collections_12_mths_ex_med', u'mths_since_last_major_derog', u'policy_code']\n",
    "\n",
    "current = df.columns\n",
    "\n",
    "for i in current:\n",
    "    if i not in expected:\n",
    "        testDict['1) Create DF - Columns'] = 'Fail'\n",
    "else:\n",
    "    testDict['1) Create DF - Columns'] = 'Pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expected data types as of 2015-09-03\n",
    "expectedDtype = {'mths_since_last_delinq': 'float64', 'inq_last_6mths': 'float64', 'grade': 'object', 'last_pymnt_amnt': 'float64', 'annual_inc': 'float64', 'out_prncp_inv': 'float64', 'total_acc': 'float64', 'fico_range_low': 'float64', 'out_prncp': 'float64', 'last_fico_range_high': 'float64', 'emp_length': 'object', 'total_pymnt': 'float64', 'fico_range_high': 'float64', 'emp_title': 'object', 'pub_rec': 'float64', 'title': 'object', 'last_fico_range_low': 'float64', 'funded_amnt_inv': 'float64', 'initial_list_status': 'object', 'total_rec_prncp': 'float64', 'next_pymnt_d': 'object', 'earliest_cr_line': 'object', 'zip_code': 'object', 'last_credit_pull_d': 'object', 'verification_status': 'object', 'total_pymnt_inv': 'float64', 'open_acc': 'float64', 'last_pymnt_d': 'object', 'collections_12_mths_ex_med': 'float64', 'dti': 'float64', 'sub_grade': 'object', 'pymnt_plan': 'object', 'purpose': 'object', 'addr_state': 'object', 'recoveries': 'float64', 'mths_since_last_record': 'float64', 'mths_since_last_major_derog': 'float64', 'desc': 'object', 'policy_code': 'float64', 'term': 'object', 'revol_bal': 'float64', 'total_rec_int': 'float64', 'installment': 'float64', 'url': 'object', 'revol_util': 'object', 'total_rec_late_fee': 'float64', 'int_rate': 'object', 'collection_recovery_fee': 'float64', 'funded_amnt': 'float64', 'member_id': 'float64', 'loan_status': 'object', 'home_ownership': 'object', 'delinq_2yrs': 'float64', 'loan_amnt': 'float64', 'issue_d': 'object'}\n",
    "\n",
    "for i in expectedDtype:\n",
    "    if str(df[i].dtype) != expectedDtype[i]:\n",
    "        testDict['1) Create DF - dType'] = 'Fail'\n",
    "else:\n",
    "    testDict['1) Create DF - dType'] = 'Pass'      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2) Add date data format and make all dates relative to appropriate date (mostly relative to issue date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Info on to_datetimes http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html\n",
    "# Converting to a Date in Words - Year in Numbers format (Jan-2015)\n",
    "def timeBetweenDatesM(timeZero, timeCompare):\n",
    "    timeZeroF = pd.to_datetime(timeZero,format=\"%b-%Y\")\n",
    "    timeCompareF = pd.to_datetime(timeCompare,format=\"%b-%Y\")\n",
    "    return (timeCompareF - timeZeroF).astype('timedelta64[M]')\n",
    "\n",
    "# Add column for today: https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior\n",
    "df['today'] = datetime.date.today().strftime(\"%b-%Y\")\n",
    "\n",
    "# Apply definition\n",
    "df['last_pymnt_d_R'] = timeBetweenDatesM(df['issue_d'], df['last_pymnt_d'])\n",
    "df['earliest_cr_line_R'] = timeBetweenDatesM(df['issue_d'], df['earliest_cr_line'])\n",
    "df['last_pymnt_d_R'] = timeBetweenDatesM(df['issue_d'], df['last_pymnt_d'])\n",
    "df['next_pymnt_d_R'] = timeBetweenDatesM(df['issue_d'], df['next_pymnt_d'])\n",
    "df['last_credit_pull_d_R'] = timeBetweenDatesM(df['issue_d'], df['last_credit_pull_d'])\n",
    "df['loan_age'] = timeBetweenDatesM(df['issue_d'], df['today'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test to see if nuber of available loans has been truncated by kicking out older loans or generally shrinking size of data. Also, test on the range of loan_age and last_pymnt_d_R variables as these are critical to the upcoming CO metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expected min loan age and number of records as of 2015-09-03\n",
    "expected_min = 9\n",
    "expected_records = 466287\n",
    "if df['loan_age'].min() != expected_min or df['loan_age'].count() < 466287:\n",
    "    testDict['2) Date Data - Data Cut'] = 'Fail'\n",
    "else:\n",
    "    testDict['2) Date Data - Data Cut'] = 'Pass'\n",
    "\n",
    "def varRangeCheck(series, acceptable_range, expected_mean, expected_25_quantile, expected_75_quantile):\n",
    "    if series.mean() > (expected_mean*(1+acceptable_range)) or series.mean() < (expected_mean*(1-acceptable_range)) or series.quantile(0.25) > (expected_25_quantile*(1+acceptable_range)) or series.quantile(0.25) < (expected_25_quantile*(1-acceptable_range)) or series.quantile(0.75) > (expected_75_quantile*(1+acceptable_range)) or series.quantile(0.75) < (expected_75_quantile*(1-acceptable_range)):\n",
    "        return 'Fail'\n",
    "    else:\n",
    "        return 'Pass'\n",
    "\n",
    "#Set acceptable variable variance\n",
    "acceptable_range = 0.05    \n",
    "\n",
    "#Expected metrics for loan age as of 2015-09-03\n",
    "expected_mean_loan_age = 24\n",
    "expected_25_loan_age = 14\n",
    "expected_75_loan_age = 30\n",
    "\n",
    "testDict['2) Date Data - loan_age Range'] = varRangeCheck(df['loan_age'], acceptable_range, expected_mean_loan_age, expected_25_loan_age, expected_75_loan_age)\n",
    "\n",
    "#Expected metrics for last_pymnt_d_R as of 2015-09-03\n",
    "expected_mean_last_pymnt_d_R = 15.4\n",
    "expected_25_last_pymnt_d_R = 8\n",
    "expected_75_last_pymnt_d_R = 20\n",
    "\n",
    "testDict['2) Date Data - last_pymnt_d_R Range'] = varRangeCheck(df['last_pymnt_d_R'], acceptable_range, expected_mean_last_pymnt_d_R, expected_25_last_pymnt_d_R, expected_75_last_pymnt_d_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3) Review CO/Default Data and eliminate out of policy loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an inPolicy flag to track accounts in Policy\n",
    "df['inPolicy'] = df['loan_status'].map(lambda i: 1 if i in [\n",
    "'Current',\n",
    "'Fully Paid',\n",
    "'Charged Off',\n",
    "'Late (31-120 days)',\n",
    "'In Grace Period',\n",
    "'Late (16-30 days)',\n",
    "'Default'\n",
    "] else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test % of inPolicy loans to make sure we don't drop more than we should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Expectation as of 09-03-2015\n",
    "if df['inPolicy'].mean() < 0.99:\n",
    "    testDict['3) Review CO Data - Out of policy data'] = 'Fail'\n",
    "else:\n",
    "    testDict['3) Review CO Data - Out of policy data'] = 'Pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop out of policy loans\n",
    "df = df[df.inPolicy == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4) Create and Add CO Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add 1/0 field for charge offs\n",
    "\n",
    "def chargeOffFlag(loan_status, last_pymnt_d_R, n):\n",
    "    if (loan_status == 'Charged Off' or loan_status == 'Default') and last_pymnt_d_R <= (n-6):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['CO18M'] = df.apply(lambda row: chargeOffFlag(row['loan_status'], row['last_pymnt_d_R'], 18), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Tests 18M CO by Sub Grade and make sure no new grades were added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expectation as of 09-03-2015\n",
    "gradeCODict = {'A':0.011836, 'B':0.025590, 'C':0.037372, 'D':0.053925, 'E':0.065756, 'F':0.093199, 'G':0.098146}\n",
    "\n",
    "#Set acceptable variable variance\n",
    "acceptable_range = 0.05    \n",
    "\n",
    "currentCODict = {}\n",
    "currentCODict = df.groupby(['grade'])['CO18M'].mean()\n",
    "\n",
    "for i in gradeCODict:\n",
    "    if currentCODict[i] > (gradeCODict[i]*(1+acceptable_range)) or currentCODict[i] < (gradeCODict[i]*(1-acceptable_range)):\n",
    "        testDict['4) Create CO Flag - CO by Grade'] = 'Fail'\n",
    "else:\n",
    "    testDict['4) Create CO Flag - CO by Grade'] = 'Pass'\n",
    "\n",
    "\n",
    "for i in currentCODict.keys():\n",
    "    if i not in gradeCODict:\n",
    "        testDict['4) Create CO Flag - CO by Grade'] = 'Fail'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5) Fix data type for revol_util and int_rate (object to float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['int_rate'] = df.int_rate.replace('%','',regex=True).astype('float')/100\n",
    "df['revol_util'] = df.revol_util.replace('%','',regex=True).astype('float')/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test variable range for fixed int_rate and revol_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set acceptable variable variance\n",
    "acceptable_range = 0.05    \n",
    "\n",
    "#Expected metrics as of 2015-09-03\n",
    "expected_mean_int_rate = 0.138\n",
    "expected_25_int_rate = 0.1099\n",
    "expected_75_int_rate = 0.1649\n",
    "\n",
    "testDict['5) Data Fix - int_rate Range'] = varRangeCheck(df['int_rate'], acceptable_range, expected_mean_int_rate, expected_25_int_rate, expected_75_int_rate)\n",
    "\n",
    "#Expected metrics as of 2015-09-03\n",
    "expected_mean_revol_util = 0.561\n",
    "expected_25_revol_util = 0.393\n",
    "expected_75_revol_util = 0.747\n",
    "\n",
    "testDict['5) Data Fix - revol_util Range'] = varRangeCheck(df['revol_util'], acceptable_range, expected_mean_revol_util, expected_25_revol_util, expected_75_revol_util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6) Drop Columns that we won't have at time of decisioning or judgementally want to exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irrelevantVariable = [\n",
    "'out_prncp',\n",
    "'out_prncp_inv',\n",
    "'total_pymnt',\n",
    "'total_pymnt_inv',\n",
    "'total_rec_prncp',\n",
    "'total_rec_int',\n",
    "'total_rec_late_fee', \n",
    "'recoveries',\n",
    "'collection_recovery_fee',\n",
    "'last_pymnt_d',\n",
    "'last_pymnt_amnt',\n",
    "'next_pymnt_d', \n",
    "'last_credit_pull_d', \n",
    "'last_fico_range_high', \n",
    "'last_fico_range_low', \n",
    "'next_pymnt_d_R', \n",
    "'last_pymnt_d_R', \n",
    "'last_credit_pull_d_R',\n",
    "'pymnt_plan',\n",
    "'loan_status', #Function of target variable\n",
    "'today', #Not relevant\n",
    "'policy_code', #Has only a single case\n",
    "'inPolicy', #Has only a single case\n",
    "'earliest_cr_line', #Has a lot of different values so dropping for now\n",
    "#Following metrics could be helpful in the future with text analytics\n",
    "'url',\n",
    "'desc',\n",
    "'title',\n",
    "'emp_title'\n",
    "]\n",
    "\n",
    "#Dataframe with only the relevant variables\n",
    "df = df.select(lambda f: f not in irrelevantVariable,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test to verify we have the right number of columns,the right final columns,  and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Expected columns as of 2015-09-03\n",
    "expectedFields = ['member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d',  'purpose', 'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'fico_range_low', 'fico_range_high', 'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', 'earliest_cr_line_R', 'loan_age', 'CO18M']\n",
    "\n",
    "current = df.columns\n",
    "\n",
    "for i in current:\n",
    "    if i not in expectedFields:\n",
    "        testDict['6) Drop Fields in DF - Expected Columns'] = 'Fail'\n",
    "else:\n",
    "    testDict['6) Drop Fields in DF - Expected Columns'] = 'Pass'\n",
    "    \n",
    "if len(current) > len(expectedFields):\n",
    "    testDict['6) Drop Fields in DF - Extra Columns'] = 'Fail'\n",
    "else:\n",
    "    testDict['6) Drop Fields in DF - Extra Columns'] = 'Pass'\n",
    "    \n",
    "#Expected data types as of 2015-09-03\n",
    "expectedDtype = {'mths_since_last_delinq': 'float64', 'earliest_cr_line_R': 'float64', 'inq_last_6mths': 'float64', 'grade': 'object', 'annual_inc': 'float64', 'total_acc': 'float64', 'emp_length': 'object', 'fico_range_high': 'float64', 'pub_rec': 'float64', 'revol_util': 'float64', 'funded_amnt_inv': 'float64', 'initial_list_status': 'object', 'zip_code': 'object', 'verification_status': 'object', 'open_acc': 'float64', 'CO18M': 'int64', 'collections_12_mths_ex_med': 'float64', 'dti': 'float64', 'sub_grade': 'object', 'purpose': 'object', 'addr_state': 'object', 'mths_since_last_record': 'float64', 'mths_since_last_major_derog': 'float64', 'term': 'object', 'revol_bal': 'float64', 'installment': 'float64', 'int_rate': 'float64', 'funded_amnt': 'float64', 'member_id': 'float64', 'fico_range_low': 'float64', 'home_ownership': 'object', 'loan_age': 'float64', 'delinq_2yrs': 'float64', 'loan_amnt': 'float64', 'issue_d': 'object'}\n",
    "\n",
    "for i in expectedDtype:\n",
    "    if str(df[i].dtype) != expectedDtype[i]:\n",
    "        testDict['6) Drop Fields in DF - dType'] = 'Fail'\n",
    "else:\n",
    "    testDict['6) Drop Fields in DF - dType'] = 'Pass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7) Clean remaining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: Dataframe with all independent variables\n",
    "Output: Dataframe with all nulls cleaned and flags for any variables imputed, capped, and floored\n",
    "\"\"\"\n",
    "def createOneMinusList(df, listStart):\n",
    "    \"\"\"\n",
    "    Input: Dataframe and a list that we will bump against the df to find the one minus of the df columns\n",
    "    Output: List of variables that is the one minus of the initial list\n",
    "    \"\"\"\n",
    "    oneMinusList = []\n",
    "    for col in df.columns:\n",
    "        if col not in listStart:\n",
    "            oneMinusList.append(col)\n",
    "    return oneMinusList\n",
    "\n",
    "def cap_and_floor(series, floor=0.01, cap=0.99):\n",
    "    \"\"\"\n",
    "    Takes in a numberic series (typically column from dataframe) and returns 4 series:\n",
    "    1) The final capped, floored, and imputed initial series - 'series'\n",
    "    2) A 1/0 flag for when an instance was floored - 'floored'\n",
    "    3) A 1/0 flag for when an instance was capped - 'capped'\n",
    "    4) A 1/0 flag for when an instance was imputed - 'imputed'\n",
    "    \n",
    "    Options:\n",
    "    - \"floor\" percentile at which to floor instances\n",
    "    - \"cap\" percentile at which to cap instances\n",
    "    \"\"\"\n",
    "    impute = (pd.isnull(series)).apply(int)\n",
    "    meanVal = series.mean()\n",
    "    series = series.fillna(meanVal)\n",
    "    \n",
    "    floorVal = series.quantile(floor)\n",
    "    floored = (series < floorVal).apply(int)\n",
    "    series = series.apply(lambda x: x if x > floorVal else floorVal)\n",
    "    \n",
    "    capVal = series.quantile(cap)\n",
    "    capped = (series > capVal).apply(int)\n",
    "    series = series.apply(lambda x: x if x < capVal else capVal)\n",
    "    \n",
    "    return series, floored, capped, impute, meanVal, floorVal, capVal\n",
    "\n",
    "def char_null_imput(series):\n",
    "    \"\"\"\n",
    "    Takes in a an object series (typically column from dataframe) and returns 2 series:\n",
    "    1) The final imputed initial series - 'series'\n",
    "    2) A 1/0 flag for when an instance was imputed - 'imputed'\n",
    "    \"\"\"\n",
    "    imputeVal = 'Null'\n",
    "    impute = (pd.isnull(series)).apply(int)\n",
    "    series = series.fillna(imputeVal)\n",
    "    \n",
    "    return series, impute, imputeVal \n",
    "\n",
    "def cleanDF(df, donotAlterList = []):\n",
    "    \"\"\"\n",
    "    Takes ins a datagrame and a list of fields not to alter (this would likely include your target variable \n",
    "    and varialbes you wouldn't want to cap/floor/impute)\n",
    "    \n",
    "    Outputs \n",
    "    1) A final cleaned dataframe all nulls should be imputed unless null fields come from list of fields not to \n",
    "    alter\n",
    "    2) A dictionary that contains the variables treatments by columns\n",
    "    \"\"\"\n",
    "    dfFinal = df[[]]\n",
    "    d_treatment = {}\n",
    "    dfDoNotAlter = df.loc[:,donotAlterList]\n",
    "    alterList = createOneMinusList(df, donotAlterList)\n",
    "    \n",
    "    dfNumeric = df.loc[:,alterList].select_dtypes(include=['number'])\n",
    "    for col in dfNumeric.columns:\n",
    "        series, floor, capped, impute, meanVal, floorVal, capVal = cap_and_floor(dfNumeric[col])\n",
    "        dfNumeric[col] = series\n",
    "        dfNumeric[col+\"_cap\"] = capped\n",
    "        dfNumeric[col+\"_floor\"] = floor\n",
    "        dfNumeric[col+\"_imputed\"] = impute\n",
    "        d_treatment[col+\"_cap\"] = capVal\n",
    "        d_treatment[col+\"_floor\"] = floorVal\n",
    "        d_treatment[col+\"_imputed\"] = meanVal\n",
    "    \n",
    "    dfObject = df.loc[:,alterList].select_dtypes(include=['object'])\n",
    "    for col in dfObject.columns:\n",
    "        series, impute, imputeVal  = char_null_imput(dfObject[col])\n",
    "        dfObject[col] = series\n",
    "        dfObject[col+\"_imputed\"] = impute\n",
    "        d_treatment[col+\"_imputed\"] = imputeVal\n",
    "        \n",
    "    dfFinal = pd.concat([dfFinal, dfDoNotAlter, dfNumeric, dfObject], axis=1, join_axes=[dfFinal.index])\n",
    "    return dfFinal, d_treatment\n",
    "\n",
    "#Create a list of variables not to alter in any way\n",
    "donotAlterList = ['member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'int_rate', 'installment', 'CO18M', 'loan_age']\n",
    "\n",
    "dfFinal, d_treatment = cleanDF(df, donotAlterList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test to verify we have the right number of columns,the right final columns,  and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Expected columns as of 2015-09-03\n",
    "expectedFields = [u'member_id', u'loan_amnt', u'funded_amnt', u'funded_amnt_inv', u'int_rate', u'installment', u'CO18M', u'loan_age', u'annual_inc', u'dti', u'delinq_2yrs', u'fico_range_low', u'fico_range_high', u'inq_last_6mths', u'mths_since_last_delinq', u'mths_since_last_record', u'open_acc', u'pub_rec', u'revol_bal', u'revol_util', u'total_acc', u'collections_12_mths_ex_med', u'mths_since_last_major_derog', u'earliest_cr_line_R', u'annual_inc_cap', u'annual_inc_floor', u'annual_inc_imputed', u'dti_cap', u'dti_floor', u'dti_imputed', u'delinq_2yrs_cap', u'delinq_2yrs_floor', u'delinq_2yrs_imputed', u'fico_range_low_cap', u'fico_range_low_floor', u'fico_range_low_imputed', u'fico_range_high_cap', u'fico_range_high_floor', u'fico_range_high_imputed', u'inq_last_6mths_cap', u'inq_last_6mths_floor', u'inq_last_6mths_imputed', u'mths_since_last_delinq_cap', u'mths_since_last_delinq_floor', u'mths_since_last_delinq_imputed', u'mths_since_last_record_cap', u'mths_since_last_record_floor', u'mths_since_last_record_imputed', u'open_acc_cap', u'open_acc_floor', u'open_acc_imputed', u'pub_rec_cap', u'pub_rec_floor', u'pub_rec_imputed', u'revol_bal_cap', u'revol_bal_floor', u'revol_bal_imputed', u'revol_util_cap', u'revol_util_floor', u'revol_util_imputed', u'total_acc_cap', u'total_acc_floor', u'total_acc_imputed', u'collections_12_mths_ex_med_cap', u'collections_12_mths_ex_med_floor', u'collections_12_mths_ex_med_imputed', u'mths_since_last_major_derog_cap', u'mths_since_last_major_derog_floor', u'mths_since_last_major_derog_imputed', u'earliest_cr_line_R_cap', u'earliest_cr_line_R_floor', u'earliest_cr_line_R_imputed', u'term', u'grade', u'sub_grade', u'emp_length', u'home_ownership', u'verification_status', u'issue_d', u'purpose', u'zip_code', u'addr_state', u'initial_list_status', u'term_imputed', u'grade_imputed', u'sub_grade_imputed', u'emp_length_imputed', u'home_ownership_imputed', u'verification_status_imputed', u'issue_d_imputed', u'purpose_imputed', u'zip_code_imputed', u'addr_state_imputed', u'initial_list_status_imputed']\n",
    "\n",
    "current = dfFinal.columns\n",
    "\n",
    "for i in current:\n",
    "    if i not in expectedFields:\n",
    "        testDict['7) Variable Clean Check  - Expected Columns'] = 'Fail'\n",
    "else:\n",
    "    testDict['7) Variable Clean Check  - Expected Columns'] = 'Pass'\n",
    "    \n",
    "if len(current) > len(expectedFields):\n",
    "    testDict['7) Variable Clean Check - Extra Columns'] = 'Fail'\n",
    "else:\n",
    "    testDict['7) Variable Clean Check - Extra Columns'] = 'Pass'\n",
    "    \n",
    "#Expected data types as of 2015-09-03\n",
    "expectedDtype = {'fico_range_high_imputed': 'int64', 'inq_last_6mths': 'float64', 'collections_12_mths_ex_med_cap': 'int64', 'revol_bal_floor': 'int64', 'emp_length': 'object', 'dti_cap': 'int64', 'mths_since_last_delinq_cap': 'int64', 'revol_util_cap': 'int64', 'dti_floor': 'int64', 'pub_rec': 'float64', 'mths_since_last_record_cap': 'int64', 'earliest_cr_line_R': 'float64', 'fico_range_low_cap': 'int64', 'grade_imputed': 'int64', 'revol_util_floor': 'int64', 'earliest_cr_line_R_floor': 'int64', 'emp_length_imputed': 'int64', 'mths_since_last_major_derog': 'float64', 'term': 'object', 'installment': 'float64', 'pub_rec_floor': 'int64', 'earliest_cr_line_R_cap': 'int64', 'home_ownership': 'object', 'zip_code': 'object', 'issue_d_imputed': 'int64', 'purpose_imputed': 'int64', 'open_acc_floor': 'int64', 'mths_since_last_delinq': 'float64', 'revol_util_imputed': 'int64', 'pub_rec_imputed': 'int64', 'total_acc_floor': 'int64', 'annual_inc_imputed': 'int64', 'revol_util': 'float64', 'inq_last_6mths_imputed': 'int64', 'fico_range_low_imputed': 'int64', 'delinq_2yrs': 'float64', 'verification_status': 'object', 'total_acc_imputed': 'int64', 'total_acc_cap': 'int64', 'inq_last_6mths_cap': 'int64', 'mths_since_last_major_derog_cap': 'int64', 'fico_range_high_floor': 'int64', 'zip_code_imputed': 'int64', 'member_id': 'float64', 'CO18M': 'int64', 'loan_amnt': 'float64', 'addr_state_imputed': 'int64', 'collections_12_mths_ex_med': 'float64', 'grade': 'object', 'mths_since_last_delinq_imputed': 'int64', 'annual_inc': 'float64', 'fico_range_high_cap': 'int64', 'funded_amnt_inv': 'float64', 'initial_list_status': 'object', 'mths_since_last_major_derog_floor': 'int64', 'fico_range_low_floor': 'int64', 'collections_12_mths_ex_med_imputed': 'int64', 'delinq_2yrs_floor': 'int64', 'revol_bal_imputed': 'int64', 'open_acc_imputed': 'int64', 'sub_grade': 'object', 'mths_since_last_record': 'float64', 'dti': 'float64', 'revol_bal': 'float64', 'mths_since_last_major_derog_imputed': 'int64', 'verification_status_imputed': 'int64', 'int_rate': 'float64', 'inq_last_6mths_floor': 'int64', 'collections_12_mths_ex_med_floor': 'int64', 'annual_inc_cap': 'int64', 'addr_state': 'object', 'loan_age': 'float64', 'dti_imputed': 'int64', 'delinq_2yrs_imputed': 'int64', 'fico_range_low': 'float64', 'total_acc': 'float64', 'fico_range_high': 'float64', 'revol_bal_cap': 'int64', 'delinq_2yrs_cap': 'int64', 'initial_list_status_imputed': 'int64', 'term_imputed': 'int64', 'earliest_cr_line_R_imputed': 'int64', 'annual_inc_floor': 'int64', 'home_ownership_imputed': 'int64', 'mths_since_last_record_floor': 'int64', 'open_acc_cap': 'int64', 'open_acc': 'float64', 'pub_rec_cap': 'int64', 'purpose': 'object', 'mths_since_last_delinq_floor': 'int64', 'mths_since_last_record_imputed': 'int64', 'funded_amnt': 'float64', 'sub_grade_imputed': 'int64', 'issue_d': 'object'}\n",
    "\n",
    "for i in expectedDtype:\n",
    "    if str(dfFinal[i].dtype) != expectedDtype[i]:\n",
    "        testDict['7) Variable Clean Check - dType'] = 'Fail'\n",
    "else:\n",
    "    testDict['7) Variable Clean Check - dType'] = 'Pass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test numeric variable ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open dictionary that has historic variable ranges\n",
    "writeLocation = '/Users/tphoran/Downloads/'\n",
    "\n",
    "with open(writeLocation+'varCheckDict.json', 'r') as fp:\n",
    "    varCheckDict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define new Mean check def\n",
    "def varMeanCheck(series, acceptable_range, expected_mean):\n",
    "    if series.mean() > (expected_mean*(1+acceptable_range)) or series.mean() < (expected_mean*(1-acceptable_range)):\n",
    "        return 'Fail'\n",
    "    else:\n",
    "        return 'Pass'\n",
    "\n",
    "#Set acceptable variable variance\n",
    "acceptable_range = 0.05 \n",
    "\n",
    "#Don't include member_id or CO18M variable\n",
    "doNotInclude = ['member_id', 'CO18M']\n",
    "Include = createOneMinusList(dfFinal, doNotInclude)\n",
    "NumericCheck = dfFinal.loc[:,Include].select_dtypes(include=['number'])\n",
    "\n",
    "#Check each column against historic dictionary with error exception handling for KeyError\n",
    "try:\n",
    "    for col in NumericCheck:\n",
    "        varDict = varCheckDict[col]\n",
    "        if '_cap' in col or '_floor' in col or '_impute' in col:\n",
    "            outcome = varMeanCheck(NumericCheck[col], acceptable_range, varDict['mean'])\n",
    "            if outcome == 'Fail':\n",
    "                testDict['7) Variable Clean Check - cap,floor,impute'] = outcome\n",
    "        else:\n",
    "            outcome = varRangeCheck(NumericCheck[col], acceptable_range, varDict['mean'], varDict['quantile_25'], varDict['quantile_75'])\n",
    "            if outcome == 'Fail':\n",
    "                testDict['7) Variable Clean Check - variable'] = outcome\n",
    "    else:\n",
    "        testDict['7) Variable Clean Check - cap,floor,impute'] = 'Pass'\n",
    "        testDict['7) Variable Clean Check - variable'] = 'Pass'\n",
    "except KeyError:\n",
    "    pass\n",
    "    testDict['7) Variable Clean Check - cap,floor,impute'] = 'Fail'\n",
    "    testDict['7) Variable Clean Check - variable'] = 'Fail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test object fields for expected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expected_zip_code = 884\n",
    "expected_issue_d = 91\n",
    "expected_addr_state = 50\n",
    "\n",
    "zip_code_flex = 9 \n",
    "issue_d_flex = 3\n",
    "addr_state_flex = 0\n",
    "\n",
    "term_list = [' 36 months', ' 60 months']\n",
    "grade_list = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "sub_grade_list = ['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
    " 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
    " 'G1', 'G2', 'G3', 'G4', 'G5']\n",
    "emp_length_list = ['1 year', '10+ years', '2 years', '3 years', '4 years', '5 years', '6 years',\n",
    " '7 years', '8 years', '9 years', '< 1 year', 'n/a']\n",
    "home_ownership_list = ['ANY', 'MORTGAGE', 'NONE', 'OTHER', 'OWN', 'RENT']\n",
    "verification_status_list = ['VERIFIED - income', 'VERIFIED - income source', 'not verified']\n",
    "purpose_list = ['car', 'credit_card', 'debt_consolidation', 'educational', 'home_improvement',\n",
    " 'house', 'major_purchase', 'medical', 'moving', 'other', 'renewable_energy',\n",
    " 'small_business', 'vacation', 'wedding']\n",
    "initial_list_status_list = ['f', 'w']\n",
    "\n",
    "\n",
    "objectsDF = dfFinal.select_dtypes(include=['object'])\n",
    "\n",
    "#Test we have same number of objects for key variables\n",
    "def variableTypes(charList, expected, flex):\n",
    "    if len(charList) > (expected+flex) or len(charList) < (expected-flex):\n",
    "        return 'Fail'\n",
    "    else:\n",
    "        return 'Pass'\n",
    "\n",
    "testDict['8) Transform Chars - number of zip codes'] = variableTypes(np.unique(objectsDF['zip_code'].values), expected_zip_code, zip_code_flex)\n",
    "testDict['8) Transform Chars - number of issue date'] = variableTypes(np.unique(objectsDF['issue_d'].values), expected_issue_d, issue_d_flex)\n",
    "testDict['8) Transform Chars - number of states'] = variableTypes(np.unique(objectsDF['addr_state'].values), expected_addr_state, addr_state_flex)\n",
    "\n",
    "#Test if we have same objects we would expect\n",
    "expectedCols = [u'term', u'grade', u'sub_grade', u'emp_length', u'home_ownership', u'verification_status', u'issue_d', u'purpose', u'zip_code', u'addr_state', u'initial_list_status']\n",
    "\n",
    "for cols in objectsDF.columns:\n",
    "    if cols not in expectedCols:\n",
    "        testDict['8) Transform Chars - disimilar objects'] = 'Fail'\n",
    "    else:\n",
    "        testDict['8) Transform Chars - disimilar objects'] = 'Pass'\n",
    "\n",
    "        \n",
    "#Test if each object has same instances as we would expect (exclude states, zip codes, and booking month)\n",
    "def variableSpecifics(charList, expectedList):\n",
    "    for e in charList:\n",
    "        if e not in expectedList:\n",
    "            return 'Fail'\n",
    "    else:\n",
    "        return 'Pass'\n",
    "\n",
    "testDict['8) Transform Chars - term'] = variableSpecifics(np.unique(objectsDF['term'].values), term_list)\n",
    "testDict['8) Transform Chars - grade'] = variableSpecifics(np.unique(objectsDF['grade'].values), grade_list)\n",
    "testDict['8) Transform Chars - sub_grade'] = variableSpecifics(np.unique(objectsDF['sub_grade'].values), sub_grade_list)\n",
    "testDict['8) Transform Chars - emp_length'] = variableSpecifics(np.unique(objectsDF['emp_length'].values), emp_length_list)\n",
    "testDict['8) Transform Chars - home_ownership'] = variableSpecifics(np.unique(objectsDF['home_ownership'].values), home_ownership_list)\n",
    "testDict['8) Transform Chars - verification_status'] = variableSpecifics(np.unique(objectsDF['verification_status'].values), verification_status_list)\n",
    "testDict['8) Transform Chars - purpose'] = variableSpecifics(np.unique(objectsDF['purpose'].values), purpose_list)\n",
    "testDict['8) Transform Chars - initial_list_status'] = variableSpecifics(np.unique(objectsDF['initial_list_status'].values), initial_list_status_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###8) Transform all object variables to mean of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def charCleanUp(seriesName, seriesTarget, dfContainer, d_treatment_charVars):\n",
    "    \"\"\"\n",
    "    Input: A numberic series from a df, a target variable from a df, the df it came from, and a dictionary\n",
    "    to use to capture variable treatment and applies changes to the df and dictionary (no return)\n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    uniqueValue = np.unique(dfContainer[seriesName].values)\n",
    "    meanDict = {}\n",
    "    dfSubset0 = dfContainer.loc[:,[seriesName, seriesTarget]]\n",
    "    for i in uniqueValue:\n",
    "        dfSubset = dfSubset0[dfSubset0[seriesName] == i]\n",
    "        meanDict[i] = round(dfSubset[seriesTarget].mean(),4)\n",
    "    meanDict['Missing'] = round(dfSubset0[seriesTarget].mean(),4)\n",
    "    dfContainer[seriesName] = dfContainer.apply(lambda row: meanDict[row[seriesName]], axis=1)\n",
    "    d_treatment_charVars[seriesName] = meanDict\n",
    "\n",
    "def dfCharCleanUp(df, d_treatment_charVars, seriesTarget, donotAlterList = []):\n",
    "    \"\"\"\n",
    "    Input: Dataframe, dictionary to capture variables treatments, the series target, and a list of columns not to\n",
    "    include\n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    alterList = createOneMinusList(df, donotAlterList)     \n",
    "    dfObject = df.loc[:,alterList].select_dtypes(include=['object'])\n",
    "    for col in dfObject.columns:\n",
    "        charCleanUp(col, seriesTarget, df, d_treatment_charVars)\n",
    "\n",
    "d_treatment_charVars = {}\n",
    "dfCharCleanUp(dfFinal, d_treatment_charVars, 'CO18M', donotAlterList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###9) Seperate data into build and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a validation sample and build sample\n",
    "dfFinalBuild = dfFinal[(dfFinal.loan_age >= 21)]\n",
    "dfFinalValidation = dfFinal[(dfFinal.loan_age >= 18) & (dfFinal.loan_age < 21)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Test if validation dataset is large enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(dfFinalValidation) > 60000: \n",
    "    testDict['9) Valiation Dataset Creation'] = 'Pass'\n",
    "else:\n",
    "    testDict['9) Valiation Dataset Creation'] = 'Fail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Save cleaned build and validation datasets and data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writeLocation = '/Users/tphoran/Downloads/'\n",
    "\n",
    "dfFinalBuild.to_csv(writeLocation+\"build_step1.csv\",',', index_col=None)\n",
    "dfFinalValidation.to_csv(writeLocation+\"validation_step1.csv\",',', index_col=None)\n",
    "\n",
    "with open(writeLocation+'d_treatment_charVars.json', 'w') as fp:\n",
    "    json.dump(d_treatment_charVars, fp)\n",
    "    \n",
    "with open(writeLocation+'d_treatment.json', 'w') as fp:\n",
    "    json.dump(d_treatment, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Test Dictionary Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8) Transform Chars - term - Pass\n",
      "8) Transform Chars - number of issue date - Pass\n",
      "1) Create DF - Columns - Pass\n",
      "7) Variable Clean Check - variable - Pass\n",
      "2) Date Data - loan_age Range - Pass\n",
      "2) Date Data - Data Cut - Pass\n",
      "6) Drop Fields in DF - Extra Columns - Pass\n",
      "6) Drop Fields in DF - Expected Columns - Pass\n",
      "8) Transform Chars - disimilar objects - Pass\n",
      "3) Review CO Data - Out of policy data - Pass\n",
      "8) Transform Chars - purpose - Pass\n",
      "8) Transform Chars - sub_grade - Pass\n",
      "8) Transform Chars - number of states - Pass\n",
      "5) Data Fix - int_rate Range - Pass\n",
      "7) Variable Clean Check - cap,floor,impute - Pass\n",
      "2) Date Data - last_pymnt_d_R Range - Fail\n",
      "8) Transform Chars - emp_length - Pass\n",
      "6) Drop Fields in DF - dType - Pass\n",
      "7) Variable Clean Check - Extra Columns - Pass\n",
      "1) Create DF - dType - Pass\n",
      "7) Variable Clean Check - dType - Pass\n",
      "8) Transform Chars - initial_list_status - Pass\n",
      "4) Create CO Flag - CO by Grade - Pass\n",
      "8) Transform Chars - grade - Pass\n",
      "8) Transform Chars - verification_status - Pass\n",
      "8) Transform Chars - number of zip codes - Pass\n",
      "5) Data Fix - revol_util Range - Pass\n",
      "8) Transform Chars - home_ownership - Pass\n",
      "7) Variable Clean Check  - Expected Columns - Pass\n",
      "9) Valiation Dataset Creation - Pass\n"
     ]
    }
   ],
   "source": [
    "for e in testDict:\n",
    "    print e,\n",
    "    print '-',\n",
    "    print testDict[e]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Code for test creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fico_range_high_imputed': 'int64', 'inq_last_6mths': 'float64', 'collections_12_mths_ex_med_cap': 'int64', 'revol_bal_floor': 'int64', 'emp_length': 'object', 'dti_cap': 'int64', 'mths_since_last_delinq_cap': 'int64', 'revol_util_cap': 'int64', 'dti_floor': 'int64', 'pub_rec': 'float64', 'mths_since_last_record_cap': 'int64', 'earliest_cr_line_R': 'float64', 'fico_range_low_cap': 'int64', 'grade_imputed': 'int64', 'revol_util_floor': 'int64', 'pymnt_plan': 'object', 'earliest_cr_line_R_floor': 'int64', 'emp_length_imputed': 'int64', 'mths_since_last_major_derog': 'float64', 'term': 'object', 'installment': 'float64', 'pub_rec_floor': 'int64', 'earliest_cr_line_R_cap': 'int64', 'home_ownership': 'object', 'zip_code': 'object', 'issue_d_imputed': 'int64', 'purpose_imputed': 'int64', 'open_acc_floor': 'int64', 'mths_since_last_delinq': 'float64', 'revol_util_imputed': 'int64', 'pub_rec_imputed': 'int64', 'total_acc_floor': 'int64', 'annual_inc_imputed': 'int64', 'revol_util': 'float64', 'inq_last_6mths_imputed': 'int64', 'fico_range_low_imputed': 'int64', 'delinq_2yrs': 'float64', 'verification_status': 'object', 'total_acc_imputed': 'int64', 'total_acc_cap': 'int64', 'inq_last_6mths_cap': 'int64', 'mths_since_last_major_derog_cap': 'int64', 'fico_range_high_floor': 'int64', 'zip_code_imputed': 'int64', 'member_id': 'float64', 'CO18M': 'int64', 'loan_amnt': 'float64', 'addr_state_imputed': 'int64', 'collections_12_mths_ex_med': 'float64', 'grade': 'object', 'mths_since_last_delinq_imputed': 'int64', 'annual_inc': 'float64', 'fico_range_high_cap': 'int64', 'funded_amnt_inv': 'float64', 'initial_list_status': 'object', 'mths_since_last_major_derog_floor': 'int64', 'fico_range_low_floor': 'int64', 'collections_12_mths_ex_med_imputed': 'int64', 'delinq_2yrs_floor': 'int64', 'revol_bal_imputed': 'int64', 'open_acc_imputed': 'int64', 'sub_grade': 'object', 'mths_since_last_record': 'float64', 'dti': 'float64', 'revol_bal': 'float64', 'mths_since_last_major_derog_imputed': 'int64', 'verification_status_imputed': 'int64', 'int_rate': 'float64', 'inq_last_6mths_floor': 'int64', 'collections_12_mths_ex_med_floor': 'int64', 'annual_inc_cap': 'int64', 'addr_state': 'object', 'loan_age': 'float64', 'pymnt_plan_imputed': 'int64', 'dti_imputed': 'int64', 'delinq_2yrs_imputed': 'int64', 'fico_range_low': 'float64', 'total_acc': 'float64', 'fico_range_high': 'float64', 'revol_bal_cap': 'int64', 'delinq_2yrs_cap': 'int64', 'initial_list_status_imputed': 'int64', 'term_imputed': 'int64', 'earliest_cr_line_R_imputed': 'int64', 'annual_inc_floor': 'int64', 'home_ownership_imputed': 'int64', 'mths_since_last_record_floor': 'int64', 'open_acc_cap': 'int64', 'open_acc': 'float64', 'pub_rec_cap': 'int64', 'purpose': 'object', 'mths_since_last_delinq_floor': 'int64', 'mths_since_last_record_imputed': 'int64', 'funded_amnt': 'float64', 'sub_grade_imputed': 'int64', 'issue_d': 'object'}\n"
     ]
    }
   ],
   "source": [
    "#Test builder create dtype dictionary\n",
    "dTypeDict = {}\n",
    "\n",
    "for i in dfFinal:\n",
    "    dTypeDict[i] = str(df[i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test Builder for variable cleaning\n",
    "def variableMetrics(series):\n",
    "    dictTemp = {}\n",
    "    dictTemp['mean'] = series.mean()\n",
    "    dictTemp['quantile_25'] = series.quantile(0.25)\n",
    "    dictTemp['quantile_75'] = series.quantile(0.75)\n",
    "    return dictTemp\n",
    "\n",
    "def variableMean(series):\n",
    "    dictTemp = {}\n",
    "    dictTemp['mean'] = series.mean()\n",
    "    return dictTemp\n",
    "\n",
    "dnal = ['member_id', 'CO18M']\n",
    "al = createOneMinusList(dfFinal, dnal)\n",
    "tempy = dfFinal.loc[:,al].select_dtypes(include=['number'])\n",
    "\n",
    "varCheckDict = {}\n",
    "\n",
    "for i in tempy:\n",
    "    if '_cap' in i or '_floor' in i or '_impute' in i:\n",
    "        varCheckDict[i] = variableMean(dfFinal[i])\n",
    "    else:\n",
    "        varCheckDict[i] = variableMetrics(dfFinal[i])\n",
    "\n",
    "#Write Dictionary to json file\n",
    "writeLocation = '/Users/tphoran/Downloads/'\n",
    "\n",
    "with open(writeLocation+'varCheckDict.json', 'w') as fp:\n",
    "    json.dump(varCheckDict, fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'term', u'grade', u'sub_grade', u'emp_length', u'home_ownership', u'verification_status', u'issue_d', u'pymnt_plan', u'purpose', u'zip_code', u'addr_state', u'initial_list_status'], dtype='object')\n",
      "expected_zip_code = 884\n",
      "expected_issue_d = 91\n",
      "expected_addr_state = 50\n",
      "term_list = [' 36 months' ' 60 months']\n",
      "grade_list = ['A' 'B' 'C' 'D' 'E' 'F' 'G']\n",
      "sub_grade_list = ['A1' 'A2' 'A3' 'A4' 'A5' 'B1' 'B2' 'B3' 'B4' 'B5' 'C1' 'C2' 'C3' 'C4' 'C5'\n",
      " 'D1' 'D2' 'D3' 'D4' 'D5' 'E1' 'E2' 'E3' 'E4' 'E5' 'F1' 'F2' 'F3' 'F4' 'F5'\n",
      " 'G1' 'G2' 'G3' 'G4' 'G5']\n",
      "emp_length_list = ['1 year' '10+ years' '2 years' '3 years' '4 years' '5 years' '6 years'\n",
      " '7 years' '8 years' '9 years' '< 1 year' 'n/a']\n",
      "home_ownership_list = ['ANY' 'MORTGAGE' 'NONE' 'OTHER' 'OWN' 'RENT']\n",
      "verification_status_list = ['VERIFIED - income' 'VERIFIED - income source' 'not verified']\n",
      "pymnt_plan_list = ['n' 'y']\n",
      "purpose_list = ['car' 'credit_card' 'debt_consolidation' 'educational' 'home_improvement'\n",
      " 'house' 'major_purchase' 'medical' 'moving' 'other' 'renewable_energy'\n",
      " 'small_business' 'vacation' 'wedding']\n",
      "initial_list_status_list = ['f' 'w']\n"
     ]
    }
   ],
   "source": [
    "#Get expectations for sizes and dictinary for expected fields\n",
    "objectsDF = dfFinal.loc[:].select_dtypes(include=['object'])\n",
    "\n",
    "print objectsDF.columns\n",
    "\n",
    "print 'expected_zip_code = '+ str(len(np.unique(objectsDF['zip_code'].values)))\n",
    "print 'expected_issue_d = '+ str(len(np.unique(objectsDF['issue_d'].values)))\n",
    "print 'expected_addr_state = '+ str(len(np.unique(objectsDF['addr_state'].values)))\n",
    "\n",
    "fieldsDict = {}\n",
    "\n",
    "for col in objectsDF.columns:\n",
    "    if col not in ['zip_code','issue_d', 'addr_state']:\n",
    "        fieldList = np.unique(objectsDF[col].values)\n",
    "        print str(col)+'_list = '+ str(fieldList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "series.mean()\n",
    "series.quantile(0.25)\n",
    "series.quantile(0.75)\n",
    "\"\"\"\n",
    "print df['revol_util'].mean()\n",
    "print df['revol_util'].quantile(0.25)\n",
    "print df['revol_util'].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
